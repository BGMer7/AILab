### 马尔科夫性质（Markov Property）

马尔科夫性质描述了一种随机过程的无记忆性：未来的状态只取决于当前状态，与过去的历史状态无关。换句话说，当前状态已经包含了对未来演化的所有必要信息。

------

#### 公式描述

给定一个随机过程 ${X_t}_{t=0}^{\infty}$，如果它满足以下条件，则称该过程具有马尔科夫性质：

$$
P(X_{t+1} | X_t, X_{t-1}, \dots, X_0) = P(X_{t+1} | X_t)
$$

其中：

- $X_t$：表示在时间 $t$ 的状态。
- $P(X_{t+1} | X_t, X_{t-1}, \dots, X_0)$：在所有过去状态已知的情况下，转移到 $X_{t+1}$ 的概率。
- 马尔科夫性质表明，该概率只与当前状态 $X_t$ 有关，而与更早的状态 $X_{t-1}, X_{t-2}, \dots$ 无关。

------

#### 扩展形式

如果随机过程是**离散状态**的马尔科夫链（Markov Chain），状态空间为 $S$，则可以定义转移概率为：

$$
P(X_{t+1} = s' | X_t = s) = P_{s, s'}
$$

其中：

- $s, s' \in S$：是状态空间中的两个状态。
- $P_{s, s'}$：从状态 $s$ 转移到状态 $s'$ 的概率。

当转移概率不随时间变化时，该马尔科夫链称为**齐次马尔科夫链**（Homogeneous Markov Chain）。此时：

$$
P(X_{t+1} = s' | X_t = s) = P(X_{t+k} = s' | X_k = s), \quad \forall k \geq 0
$$

------

#### 条件概率分布

在连续状态的马尔科夫过程（如马尔科夫决策过程，MDP）中，转移的条件概率分布可以表示为：

$$
P(X_{t+1} | X_t) = f(X_t, X_{t+1})
$$

其中 $f$ 是状态之间的转移分布。

------

#### 例子

1. **天气模型**
    如果状态 $X_t$ 表示某天的天气（如 "晴天" 或 "雨天"），则马尔科夫性质表明，明天的天气 $X_{t+1}$ 只取决于今天的天气 $X_t$，而与之前的天气无关。
2. **棋盘游戏**
    在游戏中，当前棋盘状态包含了所有必要的信息来预测下一步动作，而无需回顾整个游戏历史。

------

### 注意

以上内容是纯文本，公式均以原始 LaTeX 代码形式展示，直接复制粘贴到 Markdown 中，无需额外调整。