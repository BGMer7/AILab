[[Markov Property]]
[[Transition Matrix]]
[[Markov Reward]]


# 马尔可夫链（Markov Chain）

马尔可夫链（Markov Chain）可以说是机器学习和人工智能的基石，在强化学习、自然语言处理、金融领域、天气预测、语音识别方面都有着极其广泛的应用

> The future is independent of the past given the present
> 未来独立于过去，只基于当下。

这句人生哲理的话也代表了马尔科夫链的思想：**过去所有的信息都已经被保存到了现在的状态，基于现在就可以预测未来。**

虽然这么说可能有些极端，但是却可以大大简化模型的复杂度，因此马尔可夫链在很多时间序列模型中得到广泛的应用，比如循环神经网络 RNN，隐式马尔可夫模型 HMM 等，当然 MCMC 也需要它。



俄国数学家 Andrey Andreyevich Markov 研究并提出一个用数学方法就能解释自然变化的一般规律模型，被命名为马尔科夫链（Markov Chain）。马尔科夫链为状态空间中经过从一个状态到另一个状态的转换的[随机过程](https://link.zhihu.com/?target=https%3A//www.wolai.com/sa7hMtUm6EygDZwSbgqR2r%23rm8sdcNgjZNtF4jfsLoLwd)，该过程要求具备“**无记忆性** ”，即下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。这种特定类型的“**无记忆性** ”称作马尔可夫性质。



## 定义

一个离散时间马尔可夫链可以通过以下方式定义：

- **状态空间**$S$
- **转移概率矩阵**$P$

在每个时间步$t$，系统处于某个状态$X_t \in S$。马尔可夫性质可以表述为：

$$
P(X_{t+1} = j \mid X_t = i, X_{t-1}, \dots, X_0) = P(X_{t+1} = j \mid X_t = i), \quad \forall i, j \in S
$$

也就是说，给定当前状态$X_t$，未来状态$X_{t+1}$的概率仅由当前状态$X_t$决定。

## 转移概率矩阵

转移概率矩阵$P$描述了从一个状态到另一个状态的转移概率。若状态空间为$S = \{1, 2, \dots, N\}$，则转移矩阵$P$是一个$N \times N$的矩阵，其中第$i$行第$j$列的元素表示从状态$i$到状态$j$的转移概率，即：

$$
P_{ij} = P(X_{t+1} = j \mid X_t = i)
$$

该矩阵的每一行的元素和为 1，因为在某个状态下，系统必定转移到某个状态：

$$
\sum_{j=1}^{N} P_{ij} = 1, \quad \forall i
$$

### 状态转移矩阵的稳定性

状态转移矩阵有一个非常重要的特性，经过一定有限次数序列的转换，最终一定可以得到一个**稳定的概率分布** ，且与初始状态概率分布无关。例如：

假设我们当前股市的概率分布为：，[0.3，0.4,0.3] ，即 30% 概率的牛市，40% 概率的熊盘与 30% 的横盘。然后这个状态作为序列概率分布的初始状态t0 ，将其带入这个状态转移矩阵计算t1,t2,t3,... 的状态。代码如下：

```text
matrix = np.matrix([[0.9, 0.075, 0.025],
                    [0.15, 0.8, 0.05],
                    [0.25, 0.25, 0.5]], dtype=float)
vector1 = np.matrix([[0.3, 0.4, 0.3]], dtype=float)

for i in range(100):
    vector1 = vector1 * matrix
    print('Courrent round: {}'.format(i+1))
    print(vector1)
```

输出结果：

```text
Current round: 1
[[ 0.405   0.4175  0.1775]]
Current round: 2
[[ 0.4715   0.40875  0.11975]]
Current round: 3
[[ 0.5156  0.3923  0.0921]]
Current round: 4
[[ 0.54591   0.375535  0.078555]]
。。。。。。
Current round: 58
[[ 0.62499999  0.31250001  0.0625    ]]
Current round: 59
[[ 0.62499999  0.3125      0.0625    ]]
Current round: 60
[[ 0.625   0.3125  0.0625]]
。。。。。。
Current round: 99
[[ 0.625   0.3125  0.0625]]
Current round: 100
[[ 0.625   0.3125  0.0625]]
```

可以发现，从第 60 轮开始，我们的状态概率分布就不变了，一直保持[0.625,0.3125,0.0625] ，即 62.5% 的牛市，31.25% 的熊市与 6.25% 的横盘。

这个性质不仅对状态转移矩阵有效，对于绝大多数的其他的马尔可夫链模型的状态转移矩阵也有效。同时不光是离散状态，连续状态时也成立。

详细学习请参见：[https://zhuanlan.zhihu.com/p/38](https://zhuanlan.zhihu.com/p/38764470)



## 马尔可夫链的特性

1. **无记忆性**：系统的未来状态仅与当前状态有关，而与过去状态无关。
   
2. **稳态分布**：如果马尔可夫链经过充分多次的状态转移，其状态分布会趋向于一个稳态分布$\pi$，满足：

$$
\pi P = \pi
$$

这意味着稳态分布是转移矩阵的一个不变向量。

### 应用

马尔可夫链在很多领域都有广泛应用，如：

- **自然语言处理**：用于生成语言模型和文本预测。
- **统计学**：用于构建隐马尔可夫模型（HMM）进行序列数据建模。
- **图像处理**：用于图像分割和边缘检测。

### 示例：二维马尔可夫链

假设有两个状态$S = \{A, B\}$，并且转移概率矩阵为：

$$
P = \begin{pmatrix}
0.7 & 0.3 \\
0.4 & 0.6
\end{pmatrix}
$$

该矩阵表示从状态$A$转移到$A$的概率为 0.7，从状态$A$转移到$B$的概率为 0.3，以此类推。



有了转移概率矩阵之后，可以轻松求出多次状态转移之后的概率：

两次状态转移就是$P\cdot P$：
$$
P^2 = \begin{pmatrix}
0.7 & 0.3 \\ 
0.4 & 0.6 \end{pmatrix} \times 
\begin{pmatrix} 
0.7 & 0.3 \\ 
0.4 & 0.6 
\end{pmatrix}
=
\begin{pmatrix}
0.61 & 0.39 \\
0.52 & 0.48
\end{pmatrix}
$$


代表两次状态转移之后，A->B的概率是0.39，以此类推。



## 非马尔科夫链过程的例子

只有满足马尔科夫链的特性，才属于马尔科夫链过程。例如对于不放回的袋中取球问题：

显然当前取球的概率，不仅和我最后一次取的球的颜色有关，也和我之前每一次取球的颜色有关，所以这个过程不是一个马尔科夫链过程。

如果是放回的袋中取球问题，这就建立了一个马尔科夫随机过程。
