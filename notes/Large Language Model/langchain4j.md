# LangChain4j

[LangChain4j | LangChain4j](https://docs.langchain4j.dev/)

> 似乎文档的更新不如代码更新来得及时，建议直接阅读源代码。

# Tutorials

## Chat and Language Model

### Language Model

no longer support

### Chat Language Model

```java 
package dev.langchain4j.model.chat;

import dev.langchain4j.Experimental;
import dev.langchain4j.agent.tool.ToolSpecification;
import dev.langchain4j.data.message.AiMessage;
import dev.langchain4j.data.message.ChatMessage;
import dev.langchain4j.data.message.UserMessage;
import dev.langchain4j.model.chat.request.ChatRequest;
import dev.langchain4j.model.chat.response.ChatResponse;
import dev.langchain4j.model.output.Response;

import java.util.List;
import java.util.Set;

import static java.util.Arrays.asList;
import static java.util.Collections.emptySet;

/**
 * Represents a language model that has a chat interface.
 */
public interface ChatLanguageModel {

    /**
     * Generates a response from the model based on a message from a user.
     * This is a convenience method that receives the message from a user as a String
     * and returns only the generated response.
     *
     * @param userMessage The message from the user.
     * @return The response generated by the model.
     */
    default String generate(String userMessage) {
        return generate(UserMessage.from(userMessage)).content().text();
    }

    /**
     * Generates a response from the model based on a sequence of messages.
     * Typically, the sequence contains messages in the following order:
     * System (optional) - User - AI - User - AI - User ...
     *
     * @param messages An array of messages.
     * @return The response generated by the model.
     */
    default Response<AiMessage> generate(ChatMessage... messages) {
        return generate(asList(messages));
    }

    /**
     * Generates a response from the model based on a sequence of messages.
     * Typically, the sequence contains messages in the following order:
     * System (optional) - User - AI - User - AI - User ...
     *
     * @param messages A list of messages.
     * @return The response generated by the model.
     */
    Response<AiMessage> generate(List<ChatMessage> messages);

    /**
     * Generates a response from the model based on a list of messages and a list of tool specifications.
     * The response may either be a text message or a request to execute one of the specified tools.
     * Typically, the list contains messages in the following order:
     * System (optional) - User - AI - User - AI - User ...
     *
     * @param messages           A list of messages.
     * @param toolSpecifications A list of tools that the model is allowed to execute.
     *                           The model autonomously decides whether to use any of these tools.
     * @return The response generated by the model.
     * {@link AiMessage} can contain either a textual response or a request to execute one of the tools.
     */
    default Response<AiMessage> generate(List<ChatMessage> messages, List<ToolSpecification> toolSpecifications) {
        throw new IllegalArgumentException("Tools are currently not supported by this model");
    }

    /**
     * Generates a response from the model based on a list of messages and a single tool specification.
     * The model is forced to execute the specified tool.
     * Typically, the list contains messages in the following order:
     * System (optional) - User - AI - User - AI - User ...
     *
     * @param messages          A list of messages.
     * @param toolSpecification The specification of a tool that must be executed.
     *                          The model is forced to execute this tool.
     * @return The response generated by the model.
     * {@link AiMessage} contains a request to execute the specified tool.
     */
    default Response<AiMessage> generate(List<ChatMessage> messages, ToolSpecification toolSpecification) {
        throw new IllegalArgumentException("Tools are currently not supported by this model");
    }

    @Experimental
    default ChatResponse chat(ChatRequest request) {
        throw new UnsupportedOperationException();
    }

    @Experimental
    default Set<Capability> supportedCapabilities() {
        return emptySet();
    }
}

```



### Embedding Model

This model can translate text into an Embedding.

### Image Model

This model can generate and edit Images.

### Moderation Model

This model can check if the text contains harmful content.

### Scoring Model

This model can score (or rank) multiple pieces of text against a query, essentially determining how relevant each piece of text is to the query. This is useful for [RAG](https://docs.langchain4j.dev/tutorials/rag). These will be covered later.

### Chat Message

#### System Message

是由系统预设或开发者、模型训练者等设置的消息，用于为模型提供背景知识、任务指引、角色设定、对话规则等信息，引导模型按照特定的方式进行响应。它是模型在生成回复时所依据的内在指令或框架，通常不直接来源于用户当前对话内容，而是作为模型运行的基础配置存在。

#### User Message

是用户在与语言模型交互时输入的消息，直接反映了用户的当前需求、问题、意图或想法，是用户主动发起的对话内容，用于向模型寻求解答、建议、信息或进行交流等。

>### 功能与作用
>
>**system message**
>
>- **设定角色和风格** ：明确模型在对话中扮演的角色，如专业的医生、友好的客服、严格的导师等，并规定模型的回应风格，如正式、口语化、幽默风趣等。例如，系统消息可以设定 “你是一个专业的历史学者，以严谨且详细的风格回答用户关于历史事件的问题”，从而使模型的回复符合该角色和风格要求。
>- **提供背景信息** ：为模型提供对话所需的背景知识、上下文或特定情境信息，帮助模型更好地理解和生成与主题相关、连贯且准确的回答。比如在讨论某一历史时期的对话中，系统消息可以包含该时期的政治、经济、文化等背景介绍。
>- **定义任务和目标** ：清晰地描述模型需要完成的任务类型，如解答疑问、提供建议、生成故事、进行推理等，以及任务的具体要求和限制条件，引导模型朝着正确的方向进行思考和回答。例如 “根据用户提供的症状信息，判断可能的疾病并给出就医建议，但不进行确诊”。
>
>**user message**
>
>- **发起对话主题** ：用户消息通常用于引出对话的主题或问题，是对话的起点，决定了模型将围绕什么内容进行回答。比如用户发送 “告诉我关于人工智能的发展历程”，就明确了对话的主题是人工智能的发展。
>- **表达需求与意图** ：准确传达用户的具体需求、意图或情感，使模型能够根据不同的用户消息做出相应的回应。例如，用户消息可能是询问知识、寻求帮助、表达观点、分享经历等不同类型的意图。
>- **推动对话发展** ：在对话过程中，用户消息不断推动对话的深入和延续，通过提出后续问题、要求进一步解释或澄清、提出新的话题等方式，引导对话的走向，促使模型持续生成相关内容。
>
>### 内容与语义
>
>**system message** ：内容较为广泛，但通常具有一定的抽象性和通用性，是对模型回答问题的总体指导和规范。它可能包含一些概念、原则、规则、方法等，用于塑造模型的知识体系和思维方式，但不针对具体问题或场景进行详细阐述。
>
>**user message** ：内容具体且多样化，直接反映了用户当前的个性化需求和问题，往往与用户的实际生活、学习、工作等具体场景相关，具有明确的语义指向和即时性，需要模型针对其具体内容进行准确理解和回应。
>
>### 交互方式与呈现顺序
>
>**system message** ：在对话开始前就已经存在于模型的配置中，或者由开发者在特定对话场景下进行设置，通常不会在对话过程中频繁更改或由用户直接修改。它作为模型的内部指令，在对话中始终发挥作用，但一般不会像用户消息那样直接显示在对话界面中供用户查看。
>
>**user message** ：是用户在对话过程中实时输入的，每次用户发送消息后，模型根据该消息以及之前的对话历史（包括系统消息和之前的用户消息及模型回复）生成相应的回应，并将回应结果作为新的消息呈现给用户，如此循环往复，形成完整的对话交互过程。用户消息在对话界面中通常以明显的用户标识显示，让用户能够清晰地看到自己的发言和模型的回应之间的对应关系。

#### Ai Message

由 AI 生成的消息，通常是对 `UserMessage` 的响应。
`ChatLanguageModel`的`generate` 方法返回的是一个包含 `AiMessage` 的 `Response`。
`AiMessage` 可以包含文本响应（`String`）或工具执行请求（`ToolExecutionRequest`）。

#### Tool Execution Result Message

#### Custom Message

## Chat Memory



## Model Parameters
[[OpenAI Platform]]


## Response Streaming



## AI Services



## Agents



## Tools (Function Calling)

### High-level & Low-level

> 在 LangChain4j 这个 Java 库中，“High Level”（高级）和 “Low Level”（低级）指的是不同抽象层次的 API 或组件，它们提供了与大型语言模型（LLM）交互的不同方式：
>
> 1. **High Level API / Components (高级 API / 组件):**
>    - **目标:** 简化常见用例的开发，提供更易于使用的抽象，隐藏底层复杂性。开发者可以用更少的代码快速构建功能。
>    - 特点:
>      - **高度抽象:** 封装了许多细节，例如提示工程、模型调用、输出解析、状态管理等。
>      - **易用性:** 通常只需要进行简单的配置和调用即可实现复杂的功能。
>      - **面向常见模式:** 主要针对诸如问答、摘要、聊天机器人、工具使用（Agents）等标准场景。
>    - 例子:
>      - **`AiServices`:** 这是 LangChain4j 中一个非常高级的抽象。你只需要定义一个 Java 接口，`AiServices` 就能自动为你实现该接口，通过调用 LLM 来完成接口方法的逻辑。这极大地简化了将 LLM 功能集成到现有代码的方式。
>      - **预定义的 Chains:** 例如 `ConversationalChain`，它封装了处理带有记忆的对话的逻辑。
>      - **Agents:** 它们封装了让 LLM 决定使用哪些工具（Tools）以及如何按顺序执行以完成任务的逻辑。
> 2. **Low Level API / Components (低级 API / 组件):**
>    - **目标:** 提供更精细的控制和更大的灵活性，允许开发者直接与核心构建块交互。
>    - 特点:
>      - **更接近底层:** 提供对模型调用、提示构建、内存管理、数据嵌入等基础操作的直接访问。
>      - **灵活性:** 允许开发者根据特定需求定制复杂的、非标准的流程和逻辑。
>      - **需要更多代码和理解:** 开发者需要自己处理更多的细节，例如构建提示、解析模型输出、管理对话历史等。
>    - 例子:
>      - **直接使用 `ChatLanguageModel` 或 `LanguageModel` 接口:** 手动创建 `Prompt` 或 `ChatMessage`，直接调用模型的 `generate` 方法，并自行处理返回的 `Response`。
>      - **手动管理 `ChatMemory`:** 自己控制对话历史的存储和检索方式。
>      - **直接使用 `EmbeddingModel` 和 `EmbeddingStore`:** 手动进行文本嵌入并将向量存入/检索出向量数据库。
>      - **自定义 `PromptTemplate`:** 精细地控制如何根据输入变量构建最终发送给模型的提示。
>      - **组合基础模块:** 通过手动组合模型、提示模板、输出解析器等基础组件来构建自定义链（Chains）。
>
> **总结:**
>
> - **High Level:** 追求**简单**和**快速开发**，适合标准场景，代码量少，但灵活性相对较低。以 `AiServices` 为代表。
> - **Low Level:** 追求**灵活**和**控制**，适合定制化、复杂场景，需要更多代码和对库内部机制的理解。以直接调用 `ChatLanguageModel`、`EmbeddingModel` 等为代表。
>
> 开发者可以根据自己的需求选择合适的抽象层级。对于简单的任务或快速原型设计，高级 API 非常有用。对于需要精细控制或实现非标准工作流程的应用，则需要使用低级 API。通常，一个复杂的应用可能会混合使用这两个层级的组件。



## RAG



## Structured Outputs



# Integrations

