[[Large Language Model]]

## Conversation Chain 对话链

- **工作原理**：对话链是将之前的对话历史作为提示的一部分，传递给模型，让模型在生成新回答时参考之前的对话内容。它通过将历史对话信息存储在提示模板中，并作为新的提示内容在新一轮的对话过程中传递给模型，从而实现记忆机制。
    
- **优缺点**：优点是简单直接，能完整保留对话历史，确保模型在对话中具有完整的上下文，适用于需要自由访问早期对话历史记录的场景。缺点是随着对话轮次增加，输入的Token数量也会增加，可能导致性能下降和成本上升。

## Conversation Buffer Memory 缓冲记忆

- **原理**：将整个对话历史存储下来并传递到模型中以获取上下文。在生成响应时，模型始终回顾整个对话历史记录，以便更好地理解和响应用户。
    
- **优缺点**：优点是简单易用，适用于短期内的多轮对话，能够较好地保持上下文连贯性。缺点是随着对话的增多，存储的内容会不断增加，导致处理速度变慢，令牌消耗增大

## Conversation Buffer Window Memory 缓冲窗口记忆

- **原理**：通过设定k值，只保留一定数量（2*k）的对话轮次。每次新的互动发生时，最早的一次互动会被移除，以保证记忆的窗口长度固定。
    
- **优缺点**：优点是降低Token消耗，通过只保留最近的对话，显著减少了内存使用和计算成本，适用于长时间的对话。缺点是如果对话历史非常重要，但又不能全部保留，可能会导致模型失去一些上下文信息。

## history conversation
大模型在生成响应时，是通过将整个历史对话作为提示的一部分来回顾的。以下是详细的解释：

### 工作原理
1. **提示模板的使用**：在使用大模型进行对话时，通常会定义一个提示模板，其中包含特定的占位符，用于插入对话历史和新输入的内容。例如，在LangChain的`ConversationChain`中，提示模板可能如下所示：
   ```
   The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
   Current conversation:
   {history}
   Human: {input}
   AI:
   ```
   这里的`{history}`和`{input}`是占位符，分别用于存储对话历史和新的用户输入。

2. **存储对话历史**：当使用`ConversationBufferMemory`时，它会将所有的对话轮次存储在一个队列中。每次新的对话轮次发生时，当前的用户输入和AI响应都会被添加到这个队列中。

3. **构建新的提示输入**：在生成新的响应时，系统会将存储在`ConversationBufferMemory`中的对话历史（即队列中的内容）插入到提示模板的`{history}`占位符中，同时将新的用户输入插入到`{input}`占位符中。这样，模型在生成响应时，会基于包含完整对话历史的提示来进行文本生成。

### 举例说明
假设用户与AI进行了以下对话：
- 用户第一次输入：“我姐姐明天要过生日，我需要一束生日花束。”
- AI响应：“哦，你姐姐明天要过生日，那太棒了！我可以帮你推荐一些生日花束，你想要什么样的？我知道有很多种，比如玫瑰、康乃馨、郁金香等等。”
- 用户第二次输入：“她喜欢粉色玫瑰，颜色是粉色的。”
- AI响应：“好的，那我可以推荐一束粉色玫瑰的生日花束给你。你想要多少朵？我可以帮你定制一束，比如说十朵、二十朵或者更多？”

在第三次对话时，用户输入：“我又来了，还记得我昨天为什么要来买花吗？”此时，系统会将之前的所有对话轮次（包括用户输入和AI响应）作为对话历史，插入到提示模板的`{history}`中，构建出新的提示输入。模型基于这个包含完整对话历史的提示，就能生成连贯且符合上下文的响应：“是的，我记得你昨天来买花是因为你姐姐明天要过生日，你想要买一束粉色玫瑰的生日花束给她。”

### 优点与局限性
- **优点**：这种方式简单直接，为模型提供了完整的对话历史，有助于生成连贯且符合上下文的响应，适用于需要完整上下文的对话场景。
- **局限性**：随着对话轮次的增加，输入的Token数量也会增加，可能导致响应时间变慢和成本上升。此外，当达到模型的上下文窗口限制时，过长的对话历史可能无法被完全记住。