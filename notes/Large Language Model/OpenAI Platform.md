https://platform.openai.com/docs/overview

# API Reference

## Responses

### Create a model response



好的，这是更新后的表格，其中“Function / Meaning”列已替换为中文解释，并包含了一些扩展说明：

| Parameter Name         | Data Type            | Required? | Function / Meaning (中文解释与扩展)                          |
| ---------------------- | -------------------- | --------- | ------------------------------------------------------------ |
| `input`                | `string` or `array`  | Yes       | **功能**: 提供给模型用于生成响应的主要内容。可以是文本、图片URL或文件引用。<br />这是API调用的核心，是你希望模型处理或回应的具体信息。输入的质量和清晰度直接影响输出结果。对于支持多模态输入的模型，这里可以包含图像信息。 |
| `model`                | `string`             | Yes       | **功能**: 你想使用的具体OpenAI模型的ID（例如 `gpt-4o`, `o3`）。不同模型能力、性能和价格各异。<br />选择合适的模型对结果和成本至关重要。需要根据任务需求（如创意写作、代码生成、简单问答）来平衡模型的性能、速度和价格。 |
| `include`              | `array` or `null`    | No        | **功能**: 指定在响应输出中包含额外数据，如文件搜索结果(`file_search_call.results`)或输入/输出中的图片URL。<br />当你使用了特定的内置工具（如文件搜索）或处理了图像输入/输出时，这个参数可以让你在主响应之外获取相关的元数据或中间结果，方便进行后续处理或调试。 |
| `instructions`         | `string` or `null`   | No        | **功能**: 在输入前添加的系统消息或指令集，用于指导模型的行为、角色或任务。与`previous_response_id`一起使用时会覆盖之前的指令。<br />非常适合用来设定模型的“人设”（如“你是一个专业的旅游顾问”）或规定输出格式（如“请总是用列表形式回答”）。在多轮对话中，可以动态改变指令来调整模型后续行为。 |
| `max_output_tokens`    | `integer` or `null`  | No        | **功能**: 设定模型在其响应中能生成的最大Token数量（大致理解为单词或字符片段）。帮助控制响应长度和相关成本。<br />这是控制API成本和防止生成过长响应的有效手段。但设置过低可能会导致模型回答不完整或被截断。 |
| `metadata`             | `map`                | No        | **功能**: 最多16个键值对（字符串键/值），用于将自定义信息附加到API对象上，便于跟踪或组织。<br />可以用来存储内部用户ID、会话标签、请求来源等信息，方便在日志或数据库中查询和分析API使用情况，不影响模型响应内容。 |
| `parallel_tool_calls`  | `boolean` or `null`  | No        | **功能**: (默认为`true`) 决定模型是否可以在一个响应步骤内并行执行多个工具调用（函数调用）。<br />当模型判断需要同时调用多个外部工具（例如，查询天气和翻译文本）来生成完整回答时，开启此选项可以缩短总响应时间。如果设为`false`，模型会依次调用工具。 |
| `previous_response_id` | `string` or `null`   | No        | **功能**: 对话中紧邻的前一个响应的ID。用于维护上下文并实现多轮对话。<br />这是构建连续对话体验的关键参数。API通过此ID找回之前的对话历史，模型才能理解当前的请求是建立在之前交流的基础上的。缺少它，每次请求都会被视为独立的、无上下文的请求。 |
| `reasoning`            | `object` or `null`   | No        | **功能**: (仅限o系列模型) 专用于控制某些模型的推理过程或输出的配置选项。<br />可能用于启用或配置模型的“思考链”(Chain-of-Thought)输出，或者调整特定高级模型的内部推理策略。具体效果依赖于模型本身的设计。 |
| `service_tier`         | `string` or `null`   | No        | **功能**: (默认为`auto`) 指定处理请求的服务层级 (`auto`, `default`, `flex`)，主要与Scale Tier客户相关，用于管理用量、延迟和成本。<br />主要面向有更高性能或成本优化需求的Scale Tier订阅用户。`auto`会优先使用额度，`default`是标准层级，`flex`可能是特定优化层级。普通用户通常保持默认即可。 |
| `store`                | `boolean` or `null`  | No        | **功能**: (默认为`true`) 控制OpenAI是否应存储生成的响应，以便稍后（例如通过`previous_response_id`）引用。<br />如果你不需要维护对话状态（例如，每次请求都是一次性的），可以设为`false`以符合某些隐私要求或减少存储。但对于需要连续对话的应用，通常需要保持`true`。 |
| `stream`               | `boolean` or `null`  | No        | **功能**: 若为`true`，响应会随着生成逐步通过服务器发送事件(SSE)增量返回。若为`false`，则在完成后一次性发送完整响应。<br />对于需要实时反馈的交互式应用（如在线聊天机器人）非常重要，用户可以更快看到部分结果，提升体验。后端处理也需要适配SSE协议。 |
| `temperature`          | `number` or `null`   | No        | **功能**: (默认为`1`, 范围0-2) 控制输出的随机性。较低值(如0.2)使输出更集中、确定和保守；较高值(如0.8)使其更具创意、多样性和随机性。<br />需要事实性、重复性高的回答时用低值；需要创意写作、头脑风暴时用高值。设为0时，模型倾向于选择每个位置概率最高的词。通常建议只调整此参数或 `top_p` 之一。 |
| `text`                 | `object`             | No        | **功能**: 文本输出格式的配置，允许请求结构化的JSON输出而非纯文本。<br />当你需要API返回特定结构的JSON对象（例如，用于填充网页表单或驱动其他程序逻辑）时，使用此参数可以强制模型按预定义的模式输出，简化了后续的数据解析工作。 |
| `tool_choice`          | `string` or `object` | No        | **功能**: 控制模型如何从`tools`列表中选择要使用的工具。可以强制使用特定工具、阻止使用工具(`none`)或让模型自动决定(`auto`)。<br />提供了对模型调用外部工具（函数）行为的精细控制。例如，你可以强制模型必须调用你提供的某个计算函数来回答问题，而不是依赖它自己的可能不准确的计算。 |
| `tools`                | `array`              | No        | **功能**: 模型*可以*选择调用的可用工具列表。包括内置工具（如网页搜索）或开发者定义的自定义函数（函数调用）。<br />这是扩展模型能力、让它能与外部世界交互或执行特定任务的关键机制。通过定义函数接口，模型可以查询数据库、调用其他API、执行代码等，极大地增强了其实用性。 |
| `top_p`                | `number` or `null`   | No        | **功能**: (默认为`1`) `temperature`的替代方案，通过核采样(nucleus sampling)控制随机性。仅考虑累积概率总和达到`top_p`阈值的最小词汇集。<br />与`temperature`类似，也是控制输出多样性的方法。`top_p=0.1`意味着模型只在概率最高的10%的词中选择。较低的值使输出更保守。通常建议只调整此参数或 `temperature` 之一。 |
| `truncation`           | `string` or `null`   | No        | **功能**: (默认为`disabled`) 处理输入（包括历史对话）超出模型上下文窗口限制的策略。`disabled`会使请求失败；`auto`会自动截断较早的消息。<br />对于长对话场景，这是一个重要的容错机制。`auto`可以避免因上下文超长而导致请求失败，但要注意它可能会丢弃对话中间的部分信息，影响连贯性。 |
| `user`                 | `string`             | No        | **功能**: 代表发出请求的最终用户的唯一标识符。帮助OpenAI监控和检测潜在的滥用行为。<br />提供此ID有助于OpenAI区分来自不同终端用户的请求，对识别和处理API滥用、以及潜在的个性化服务（如果未来支持）有帮助。建议为你的应用中的每个最终用户设置一个稳定且唯一的ID。 |



## Streaming





## Chat Completions







