{
  "main": {
    "id": "0c0f889539bc55c2",
    "type": "split",
    "children": [
      {
        "id": "8c68d4696d8a8ec6",
        "type": "tabs",
        "children": [
          {
            "id": "7dba5258c214ba18",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "Math-Foundation/Probability-Statistics/Markov Reward.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Markov Reward"
            }
          },
          {
            "id": "6e694695f8535239",
            "type": "leaf",
            "state": {
              "type": "graph",
              "state": {},
              "icon": "lucide-git-fork",
              "title": "Graph view"
            }
          }
        ]
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "6e6a4f8fefe5ac07",
    "type": "split",
    "children": [
      {
        "id": "c181bb727cebee03",
        "type": "tabs",
        "children": [
          {
            "id": "a1824f8d5f308bc5",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-folder-closed",
              "title": "Files"
            }
          },
          {
            "id": "33c5a849237d2d26",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "Search"
            }
          },
          {
            "id": "516078e64b41b93a",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "Bookmarks"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300
  },
  "right": {
    "id": "e94daf5b3de87423",
    "type": "split",
    "children": [
      {
        "id": "c35d1bbfdab8183d",
        "type": "tabs",
        "children": [
          {
            "id": "69e7dfc6db19d520",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "Deep-Learning/Object-Detection/Region of Interest(RoI).md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-coming-in",
              "title": "Backlinks for Region of Interest(RoI)"
            }
          },
          {
            "id": "c139a2d40839c52a",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "Deep-Learning/Object-Detection/Region of Interest(RoI).md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-going-out",
              "title": "Outgoing links from Region of Interest(RoI)"
            }
          },
          {
            "id": "fb313b345ff9dba0",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              },
              "icon": "lucide-tags",
              "title": "Tags"
            }
          },
          {
            "id": "e28e0ced90c6adce",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "Math-Foundation/Probability-Statistics/Markov Reward.md"
              },
              "icon": "lucide-list",
              "title": "Outline of Markov Reward"
            }
          }
        ],
        "currentTab": 3
      }
    ],
    "direction": "horizontal",
    "width": 300
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false
    }
  },
  "active": "7dba5258c214ba18",
  "lastOpenFiles": [
    "Math-Foundation/Probability-Statistics/Pure Sampling.md",
    "Math-Foundation/Probability-Statistics/Bellman Equation.md",
    "Math-Foundation/Probability-Statistics/Markov Reward.md",
    "Math-Foundation/Probability-Statistics/Markov Property.md",
    "Pasted image 20241129111755.png",
    "Reinforcement-Learning/Markov Reward Process(MRP).md",
    "Reinforcement-Learning/Reinforcement Learning.md",
    "Reinforcement-Learning/Markov Decision Process(MDP).md",
    "Math-Foundation/Probability-Statistics/Markov Chain.md",
    "Math-Foundation/Probability-Statistics/Transition Matrix.md",
    "Math-Foundation/Probability-Statistics/Stochastic Process.md",
    "Reinforcement-Learning/Policy based RL.md",
    "Math-Foundation/Probability-Statistics/conditional probability.md",
    "Reinforcement-Learning/Value based RL.md",
    "Reinforcement-Learning/State.md",
    "Reinforcement-Learning/Reward.md",
    "Reinforcement-Learning/Policy.md",
    "Reinforcement-Learning/Actor-Critic.md",
    "Reinforcement-Learning/Agent.md",
    "Reinforcement-Learning/Action.md",
    "Machine-Learning/Supervised Learning.md",
    "references.md",
    "Reinforcement-Learning/Environment.md",
    "Reinforcement-Learning",
    "Math-Foundation/Linear-Algebra/Singular Value Decomposition(SVD).md",
    "Math-Foundation/Linear-Algebra/Eigen Value Decomposition(EVD).md",
    "Deep-Learning/Object-Detection/Region of Interest(RoI).md",
    "Untitled.canvas",
    "PyTorch",
    "Deep-Learning/Hidden Layer.jpeg",
    "Deep-Learning/屏幕截图_10-11-2024_222827_zhuanlan.zhihu.com.jpeg.crdownload",
    "Deep-Learning/屏幕截图_10-11-2024_222648_zhuanlan.zhihu.com.jpeg.crdownload",
    "Deep-Learning/Untitled",
    "Deep-Learning/Learning-Rate",
    "Deep-Learning",
    "Math-Foundation/Linear-Algebra/norm.py",
    "Math-Foundation/Linear-Algebra/linear_algebra.py",
    "Math-Foundation/Linear-Algebra/eigenvalue.py"
  ]
}