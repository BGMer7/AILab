[[11-point interpolation]]
[[Receiver Operating Characteristic Curve (ROC)]]

**AUC**（Area Under the Curve）是用来评估分类模型性能的一种指标，特别是在二分类任务中。AUC 衡量的是 **ROC 曲线**（Receiver Operating Characteristic Curve）下的面积，AUC 的值介于 0 和 1 之间，通常被用来评估模型在不同的 **阈值** 下的 **分类能力**。

### **AUC（Area Under the Curve）**
**AUC** 实际上是 **ROC 曲线** 下的面积，ROC 曲线是通过绘制模型在不同阈值下的 **True Positive Rate (TPR)** 和 **False Positive Rate (FPR)** 来得到的。AUC 越大，表示模型的性能越好。AUC 适用于评估模型的 **区分能力**，即模型能否正确地区分正类和负类。

### **1. 计算 AUC**
**AUC** 的计算基于 ROC 曲线的面积。下面是计算步骤：
#### 1.1 **ROC 曲线**
- **True Positive Rate (TPR)**：也叫召回率（Recall），表示模型识别出的正类样本占所有正类样本的比例：
    $$TPR = \frac{TP}{TP + FN}$$
    其中，TP 为真正类（True Positives），FN 为假负类（False Negatives）。
- **False Positive Rate (FPR)**：表示模型错误识别为正类的负类样本占所有负类样本的比例：
    $$FPR = \frac{FP}{FP + TN}$$
    其中，FP 为假正类（False Positives），TN 为真负类（True Negatives）。

通过调整分类阈值，我们可以得到不同的 TPR 和 FPR 值。将这些点绘制在 **FPR** 和 **TPR** 的坐标系中，就形成了 **ROC 曲线**。

#### 1.2 **AUC 的意义**

- **AUC = 1**：表示模型完美地分开了正类和负类，也就是说，模型能够在所有的阈值下都正确地预测正类和负类。
- **AUC = 0.5**：表示模型的性能相当于随机猜测，无法有效区分正类和负类。
- **AUC < 0.5**：表示模型的性能比随机猜测还差，通常表明模型输出的类别标签存在严重问题。

#### 1.3 **AUC 的计算方法**

AUC 的计算通常使用数值积分的方法，尤其是 **梯形规则**，将 ROC 曲线下的面积近似为多个梯形的面积之和。这种方法适用于 ROC 曲线包含多个点的情形。

### **2. AUC 在分类任务中的应用**

- **区分能力**：AUC 衡量的是模型在不同阈值下的分类能力。AUC 越大，表示模型区分正类和负类的能力越强。
- **不受类不平衡影响**：与单独使用精确度（Precision）和召回率（Recall）不同，AUC 是一个整体指标，能够综合考虑模型的性能，且不容易受到类别不平衡（类不均衡问题）的影响。因此，它特别适合用于二分类问题，尤其是在正负样本比例不均衡的情况下。
- **评估标准**：AUC 在模型比较中非常有用，尤其是当你有多个模型或者多个阈值时，AUC 可以帮助你选择最佳的模型。

### **3. AUC 和 ROC 曲线的关系**

**ROC 曲线** 和 **AUC** 紧密相关。ROC 曲线展示了模型在各种阈值下的表现，而 AUC 则是这条曲线下的面积，它为模型的整体分类能力提供了一个数值指标。

- **ROC 曲线的纵轴（TPR）**：召回率。
- **ROC 曲线的横轴（FPR）**：假阳性率。

随着 **阈值** 从 0 到 1 变化，模型的 **TPR** 和 **FPR** 也会发生变化，从而形成 ROC 曲线。

### **4. AUC 的优缺点**

#### 4.1 **优点**

- **稳定性**：AUC 不受类不平衡的影响。即使数据集中的正负样本比例严重不平衡，AUC 仍然能提供一个稳定的评估。
- **综合评估**：AUC 综合考虑了不同阈值下的表现，能够从全局的角度评估模型的分类能力。

#### 4.2 **缺点**

- **不适用于回归任务**：AUC 仅适用于分类任务，特别是二分类任务。对于回归问题，AUC 并不适用。
- **计算复杂度**：尽管 AUC 提供了一个全面的评估标准，但在某些情况下，计算 AUC 可能比其他评估指标（如准确率）更加复杂。

### **5. AUC 示例**

假设你有一个二分类模型，预测结果如下所示：

|实际标签|预测概率（模型输出）|
|---|---|
|1|0.9|
|1|0.8|
|0|0.7|
|1|0.6|
|0|0.5|
|0|0.4|
|1|0.3|
|0|0.2|

你可以通过调整分类的阈值（比如 0.5），并计算对应的 **TPR** 和 **FPR**，然后画出 **ROC 曲线**。通过数值积分的方法，你可以计算得到 **AUC**。

### **6. AUC 的常见使用场景**

- **二分类问题**：AUC 是二分类问题中最常见的评估指标之一，尤其是当数据集存在类别不平衡时。
- **信用评分**：在金融领域，AUC 被用来评估信用评分模型的效果。
- **疾病检测**：在医学诊断中，AUC 经常用于评估疾病检测模型的性能。
- **推荐系统**：AUC 也用于评估推荐系统中预测某个物品是否对用户有吸引力的能力。

### **总结**

AUC（Area Under the Curve）是一个常用的分类评估指标，表示 **ROC 曲线** 下的面积。它衡量了模型区分正类和负类的能力，具有较高的稳定性，尤其适用于数据不平衡的场景。AUC 的值越大，表示模型的分类能力越强。