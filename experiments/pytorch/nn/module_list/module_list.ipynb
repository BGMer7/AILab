{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "layers = nn.ModuleList([\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=10, out_features=20, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=20, out_features=5, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(layers[0])\n",
    "print(layers[1])\n",
    "print(layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "layers.append(nn.Linear(5, 2))\n",
    "print(len(layers))  # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 5)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # 每个模块单独前向传播\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq = nn.Sequential(\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 5)\n",
    ")\n",
    "\n",
    "output = model(torch.randn(1, 10))  # 直接传入数据即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4142,  0.4323,  1.8367,  0.6806, -0.0357]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(in_features, in_features),  # 第一个全连接层\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features, in_features)   # 第二个全连接层\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x  # 保存输入 x（残差连接）\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)  # 逐层执行计算\n",
    "        # Residual connect: output = x + f(x)\n",
    "        return x + identity  # 添加残差连接\n",
    "\n",
    "# 测试\n",
    "x = torch.randn(1, 5)  # 生成输入数据\n",
    "res_block = ResidualBlock(5)  # 创建残差块\n",
    "output = res_block(x)  # 计算输出\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4532, -0.2639, -0.7839, -1.1680, -0.8791]], grad_fn=<AddBackward0>)\n",
      "<bound method Module.children of ResidualNetwork(\n",
      "  (res_blocks): ModuleList(\n",
      "    (0-2): 3 x ResidualBlock(\n",
      "      (layers): ModuleList(\n",
      "        (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "class ResidualNetwork(nn.Module):\n",
    "    def __init__(self, num_blocks, in_features):\n",
    "        super().__init__()\n",
    "        self.res_blocks = nn.ModuleList([ResidualBlock(in_features) for _ in range(num_blocks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x)  # 每个残差块都会执行跳跃连接\n",
    "        return x\n",
    "\n",
    "# 测试\n",
    "x = torch.randn(1, 5)\n",
    "model = ResidualNetwork(3, 5)  # 3 层残差网络\n",
    "output = model(x)\n",
    "print(output)\n",
    "\n",
    "print(model.children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel-dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
