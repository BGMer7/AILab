{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([3, 5])\n",
      "Output data: tensor([[ 0.8077,  0.7671, -1.3354, -0.8978,  1.0544],\n",
      "        [ 0.3077,  0.3016, -0.4576, -0.8128,  0.9606],\n",
      "        [ 0.0640,  0.3347,  0.4794,  0.2482,  0.0634]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥å±‚\n",
    "fc = nn.Linear(10, 5)  # è¾“å…¥ç‰¹å¾ç»´åº¦ä¸º 10ï¼Œè¾“å‡ºç»´åº¦ä¸º 5\n",
    "\n",
    "# è¾“å…¥æ•°æ®\n",
    "input_data = torch.randn(3, 10)  # 3 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ 10 ä¸ªç‰¹å¾\n",
    "\n",
    "# å‰å‘ä¼ æ’­\n",
    "output = fc(input_data)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output data:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Linearçš„åˆå§‹åŒ–æ˜¯kaimingåˆå§‹åŒ–ï¼Œæƒé‡éšæœºï¼Œå¹¶ä¸”æœä»kaimingæ­£æ€åˆ†å¸ƒï¼Œæˆ–è€…kaimingå‡åŒ€åˆ†å¸ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights shape: torch.Size([5, 10])\n",
      "Weights: Parameter containing:\n",
      "tensor([[ 0.2481,  0.2493,  0.0071, -0.1585, -0.2911,  0.2051, -0.2996,  0.1113,\n",
      "         -0.0541,  0.1248],\n",
      "        [-0.2266, -0.2820,  0.1351,  0.0176, -0.2856, -0.2698,  0.2831, -0.1588,\n",
      "          0.1559,  0.0903],\n",
      "        [-0.2083, -0.0895, -0.1894, -0.0167,  0.2028,  0.0179, -0.3083,  0.0767,\n",
      "         -0.1286, -0.3130],\n",
      "        [-0.0173, -0.2401,  0.1969, -0.2898,  0.2351, -0.2757, -0.0765, -0.0886,\n",
      "         -0.1438, -0.3039],\n",
      "        [-0.0906,  0.1289, -0.1114,  0.2279, -0.1368,  0.2503,  0.1781, -0.1895,\n",
      "          0.1165,  0.2085]], requires_grad=True)\n",
      "Bias shape: torch.Size([5])\n",
      "Bias: Parameter containing:\n",
      "tensor([ 0.2559, -0.1903, -0.2190, -0.1814,  0.2980], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# æŸ¥çœ‹æƒé‡\n",
    "print(\"Weights shape:\", fc.weight.shape)\n",
    "print(\"Weights:\", fc.weight)\n",
    "\n",
    "# æŸ¥çœ‹åç½®\n",
    "print(\"Bias shape:\", fc.bias.shape)\n",
    "print(\"Bias:\", fc.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6059,  0.1285,  0.4780, -0.4500, -0.0201],\n",
       "        [-0.8102,  0.7428, -0.3083,  0.4793, -0.0139],\n",
       "        [-0.9811,  0.0890, -1.1209, -0.1263, -1.2466]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªæƒé‡å¼ é‡\n",
    "weight_tensor = torch.empty(3, 5)  # å‡è®¾è¾“å‡ºç»´åº¦ä¸º 3ï¼Œè¾“å…¥ç»´åº¦ä¸º 5\n",
    "\n",
    "# modeï¼šå¯ä»¥æ˜¯ 'fan_in' æˆ– 'fan_out'ã€‚'fan_in' ç”¨äºæ­£å‘ä¼ æ’­ï¼Œ'fan_out' ç”¨äºåå‘ä¼ æ’­ã€‚\n",
    "# nonlinearityï¼šæŒ‡å®šæ¿€æ´»å‡½æ•°ï¼Œé€šå¸¸ä¸º 'relu' æˆ– 'leaky_relu'ã€‚\n",
    "\n",
    "# ä½¿ç”¨ Kaiming Normal åˆå§‹åŒ–\n",
    "init.kaiming_normal_(weight_tensor, mode='fan_in', nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2740, -0.3445, -0.3596,  0.3580,  0.4891],\n",
       "        [ 0.6418,  0.8994, -0.2666,  0.1239, -0.7271],\n",
       "        [-0.5327, -1.0143,  1.0899, -0.5319, -0.3720]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä½¿ç”¨ Kaiming Uniform åˆå§‹åŒ–\n",
    "init.kaiming_uniform_(weight_tensor, mode='fan_in', nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ nn.Linear å®Œå…¨ä½¿ç”¨æŒ‡å—\n",
      "======================================================================\n",
      "ğŸ¯ nn.Linear åŸºç¡€ç”¨æ³•\n",
      "==================================================\n",
      "ğŸ“Š çº¿æ€§å±‚ä¿¡æ¯:\n",
      "   è¾“å…¥ç»´åº¦: 3\n",
      "   è¾“å‡ºç»´åº¦: 5\n",
      "   æƒé‡å½¢çŠ¶: torch.Size([5, 3])\n",
      "   åç½®å½¢çŠ¶: torch.Size([5])\n",
      "\n",
      "ğŸ” å‚æ•°è¯¦æƒ…:\n",
      "   æƒé‡çŸ©é˜µ W:\n",
      "tensor([[-0.4768,  0.3516,  0.0821],\n",
      "        [-0.0012, -0.2304, -0.2823],\n",
      "        [-0.1321, -0.1995,  0.0219],\n",
      "        [ 0.2142, -0.3229,  0.3560],\n",
      "        [ 0.0937,  0.1607, -0.2104]])\n",
      "   åç½®å‘é‡ b:\n",
      "tensor([-0.0685, -0.4356,  0.2827,  0.3736, -0.5558])\n",
      "\n",
      "âš¡ å‰å‘ä¼ æ’­:\n",
      "   è¾“å…¥: tensor([[1., 2., 3.]])\n",
      "   è¾“å…¥å½¢çŠ¶: torch.Size([1, 3])\n",
      "   è¾“å‡º: tensor([[ 0.4041, -1.7445, -0.1827,  1.0100, -0.7719]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "   è¾“å‡ºå½¢çŠ¶: torch.Size([1, 5])\n",
      "\n",
      "âœ… æ‰‹åŠ¨è®¡ç®—éªŒè¯:\n",
      "   y = xW^T + b\n",
      "   æ‰‹åŠ¨è®¡ç®—ç»“æœ: tensor([[ 0.4041, -1.7445, -0.1827,  1.0100, -0.7719]], grad_fn=<AddBackward0>)\n",
      "   æ˜¯å¦ç›¸ç­‰: True\n",
      "\n",
      "ğŸ“¦ æ‰¹å¤„ç†ç¤ºä¾‹\n",
      "==================================================\n",
      "å•ä¸ªæ ·æœ¬:\n",
      "   è¾“å…¥å½¢çŠ¶: torch.Size([4])\n",
      "   è¾“å‡ºå½¢çŠ¶: torch.Size([2])\n",
      "\n",
      "æ‰¹å¤„ç†:\n",
      "   è¾“å…¥å½¢çŠ¶: torch.Size([3, 4])\n",
      "   è¾“å‡ºå½¢çŠ¶: torch.Size([3, 2])\n",
      "\n",
      "é«˜ç»´æ‰¹å¤„ç†:\n",
      "   è¾“å…¥å½¢çŠ¶: torch.Size([2, 5, 4])\n",
      "   è¾“å‡ºå½¢çŠ¶: torch.Size([2, 5, 2])\n",
      "   ğŸ“ æ³¨æ„: Linearåªå¯¹æœ€åä¸€ç»´è¿›è¡Œå˜æ¢\n",
      "\n",
      "ğŸ² å‚æ•°åˆå§‹åŒ–\n",
      "==================================================\n",
      "é»˜è®¤åˆå§‹åŒ–:\n",
      "   æƒé‡èŒƒå›´: [-0.441, 0.501]\n",
      "   åç½®èŒƒå›´: [-0.530, 0.162]\n",
      "\n",
      "Xavieråˆå§‹åŒ–:\n",
      "   æƒé‡èŒƒå›´: [-1.020, 0.674]\n",
      "   åç½®: Parameter containing:\n",
      "tensor([0., 0.], requires_grad=True)\n",
      "\n",
      "è‡ªå®šä¹‰åˆå§‹åŒ–:\n",
      "   æƒé‡:\n",
      "Parameter containing:\n",
      "tensor([[0.1000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 0.1000]], requires_grad=True)\n",
      "   åç½®: Parameter containing:\n",
      "tensor([0., 0.], requires_grad=True)\n",
      "\n",
      "ğŸš« æ— åç½®å±‚\n",
      "==================================================\n",
      "æ— åç½®çº¿æ€§å±‚:\n",
      "   æƒé‡å½¢çŠ¶: torch.Size([2, 3])\n",
      "   æ˜¯å¦æœ‰åç½®: False\n",
      "\n",
      "ğŸ“Š å¯¹æ¯”:\n",
      "   è¾“å…¥: tensor([[-0.7042, -0.5253,  0.1248]])\n",
      "   æ— åç½®è¾“å‡º: tensor([[-0.1513,  0.2838]], grad_fn=<MmBackward0>)\n",
      "   æœ‰åç½®è¾“å‡º: tensor([[0.1302, 0.4546]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "ğŸ§  å¤šå±‚æ„ŸçŸ¥æœº (MLP)\n",
      "==================================================\n",
      "MLPç»“æ„:\n",
      "SimpleMLP(\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "ğŸ“Š å‚æ•°ç»Ÿè®¡:\n",
      "   fc1.weight: torch.Size([20, 10]) -> 200 ä¸ªå‚æ•°\n",
      "   fc1.bias: torch.Size([20]) -> 20 ä¸ªå‚æ•°\n",
      "   fc2.weight: torch.Size([20, 20]) -> 400 ä¸ªå‚æ•°\n",
      "   fc2.bias: torch.Size([20]) -> 20 ä¸ªå‚æ•°\n",
      "   fc3.weight: torch.Size([3, 20]) -> 60 ä¸ªå‚æ•°\n",
      "   fc3.bias: torch.Size([3]) -> 3 ä¸ªå‚æ•°\n",
      "   æ€»å‚æ•°é‡: 703\n",
      "\n",
      "âš¡ å‰å‘ä¼ æ’­:\n",
      "   è¾“å…¥å½¢çŠ¶: torch.Size([5, 10])\n",
      "   è¾“å‡ºå½¢çŠ¶: torch.Size([5, 3])\n",
      "\n",
      "ğŸ¤– Transformerä¸­çš„Linearå±‚\n",
      "==================================================\n",
      "Transformerå‚æ•°:\n",
      "   d_model: 512\n",
      "   heads: 8\n",
      "   d_k: 64\n",
      "\n",
      "ğŸ” æ³¨æ„åŠ›çº¿æ€§å±‚:\n",
      "   Qçº¿æ€§å±‚: 512 -> 512\n",
      "   Kçº¿æ€§å±‚: 512 -> 512\n",
      "   Vçº¿æ€§å±‚: 512 -> 512\n",
      "   è¾“å‡ºå±‚: 512 -> 512\n",
      "\n",
      "ğŸ½ï¸ å‰é¦ˆç½‘ç»œ:\n",
      "   ç¬¬ä¸€å±‚: 512 -> 2048\n",
      "   ç¬¬äºŒå±‚: 2048 -> 512\n",
      "\n",
      "ğŸ“Š æ•°æ®æµ:\n",
      "   è¾“å…¥: torch.Size([2, 10, 512])\n",
      "   Q,K,V: torch.Size([2, 10, 512])\n",
      "   å‰é¦ˆè¾“å‡º: torch.Size([2, 10, 512])\n",
      "\n",
      "ğŸ’¡ å®ç”¨æŠ€å·§\n",
      "==================================================\n",
      "ğŸ¯ é€‰æ‹©è¾“å…¥è¾“å‡ºç»´åº¦:\n",
      "   - è¾“å…¥ç»´åº¦å¿…é¡»ä¸æ•°æ®æœ€åä¸€ç»´åŒ¹é…\n",
      "   - è¾“å‡ºç»´åº¦æ ¹æ®ä»»åŠ¡éœ€æ±‚ç¡®å®š\n",
      "   - å¸¸ç”¨ç»´åº¦: 64, 128, 256, 512, 768, 1024\n",
      "\n",
      "ğŸ”§ å‚æ•°åˆå§‹åŒ–:\n",
      "   - é»˜è®¤: Kaimingåˆå§‹åŒ– (é€‚åˆReLU)\n",
      "   - Xavier: é€‚åˆSigmoid/Tanh\n",
      "   - è‡ªå®šä¹‰: æ ¹æ®å…·ä½“éœ€æ±‚\n",
      "\n",
      "âš¡ æ€§èƒ½ä¼˜åŒ–:\n",
      "   - æ‰¹å¤„ç†æé«˜æ•ˆç‡\n",
      "   - GPUåŠ é€Ÿè®¡ç®—\n",
      "   - æ··åˆç²¾åº¦è®­ç»ƒ\n",
      "\n",
      "ğŸ› å¸¸è§é”™è¯¯:\n",
      "   - ç»´åº¦ä¸åŒ¹é…: æ£€æŸ¥in_features\n",
      "   - æ¢¯åº¦æ¶ˆå¤±: æ³¨æ„åˆå§‹åŒ–å’Œæ¿€æ´»å‡½æ•°\n",
      "   - è¿‡æ‹Ÿåˆ: æ·»åŠ dropoutæˆ–æ­£åˆ™åŒ–\n",
      "\n",
      "ğŸ†š Linear vs Conv å¯¹æ¯”\n",
      "==================================================\n",
      "Linearå±‚ (å…¨è¿æ¥):\n",
      "   å‚æ•°é‡: 7,850\n",
      "   ç‰¹ç‚¹: æ¯ä¸ªè¾“å…¥éƒ½è¿æ¥åˆ°æ¯ä¸ªè¾“å‡º\n",
      "\n",
      "Convå±‚ (å·ç§¯):\n",
      "   å‚æ•°é‡: 100\n",
      "   ç‰¹ç‚¹: å±€éƒ¨è¿æ¥ï¼Œæƒé‡å…±äº«\n",
      "\n",
      "ğŸ“‹ ä½¿ç”¨åœºæ™¯:\n",
      "   Linear: åˆ†ç±»å±‚ã€å…¨è¿æ¥ç½‘ç»œã€Transformer\n",
      "   Conv: å›¾åƒå¤„ç†ã€ç‰¹å¾æå–ã€CNN\n",
      "\n",
      "ğŸ”§ è°ƒè¯•Linearå±‚\n",
      "==================================================\n",
      "ğŸ” å‚æ•°æ£€æŸ¥:\n",
      "   æƒé‡æ˜¯å¦éœ€è¦æ¢¯åº¦: True\n",
      "   åç½®æ˜¯å¦éœ€è¦æ¢¯åº¦: True\n",
      "   æƒé‡æ¢¯åº¦: None\n",
      "\n",
      "âš¡ æ¢¯åº¦ä¿¡æ¯:\n",
      "   è¾“å…¥æ¢¯åº¦å½¢çŠ¶: torch.Size([2, 5])\n",
      "   æƒé‡æ¢¯åº¦å½¢çŠ¶: torch.Size([3, 5])\n",
      "   åç½®æ¢¯åº¦å½¢çŠ¶: torch.Size([3])\n",
      "\n",
      "âœ… æ¢¯åº¦æ£€æŸ¥:\n",
      "   æƒé‡æ¢¯åº¦èŒƒå›´: [-1.6369, 2.5533]\n",
      "   æ˜¯å¦æœ‰NaN: False\n",
      "\n",
      "ğŸŠ nn.Linear æ•™ç¨‹å®Œæˆ!\n",
      "è®°ä½: Linearå±‚å°±æ˜¯ y = xW^T + b çš„çŸ©é˜µè¿ç®—ï¼\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def basic_linear_layer():\n",
    "    \"\"\"nn.Linear åŸºç¡€ç”¨æ³•\"\"\"\n",
    "    print(\"ğŸ¯ nn.Linear åŸºç¡€ç”¨æ³•\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # åˆ›å»ºçº¿æ€§å±‚ï¼šè¾“å…¥3ç»´ï¼Œè¾“å‡º5ç»´\n",
    "    linear = nn.Linear(in_features=3, out_features=5)\n",
    "    \n",
    "    print(f\"ğŸ“Š çº¿æ€§å±‚ä¿¡æ¯:\")\n",
    "    print(f\"   è¾“å…¥ç»´åº¦: {linear.in_features}\")\n",
    "    print(f\"   è¾“å‡ºç»´åº¦: {linear.out_features}\")\n",
    "    print(f\"   æƒé‡å½¢çŠ¶: {linear.weight.shape}\")\n",
    "    print(f\"   åç½®å½¢çŠ¶: {linear.bias.shape}\")\n",
    "    \n",
    "    # æŸ¥çœ‹å‚æ•°\n",
    "    print(f\"\\nğŸ” å‚æ•°è¯¦æƒ…:\")\n",
    "    print(f\"   æƒé‡çŸ©é˜µ W:\\n{linear.weight.data}\")\n",
    "    print(f\"   åç½®å‘é‡ b:\\n{linear.bias.data}\")\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    input_data = torch.tensor([[1.0, 2.0, 3.0]])  # [1, 3]\n",
    "    output = linear(input_data)\n",
    "    \n",
    "    print(f\"\\nâš¡ å‰å‘ä¼ æ’­:\")\n",
    "    print(f\"   è¾“å…¥: {input_data}\")\n",
    "    print(f\"   è¾“å…¥å½¢çŠ¶: {input_data.shape}\")\n",
    "    print(f\"   è¾“å‡º: {output}\")\n",
    "    print(f\"   è¾“å‡ºå½¢çŠ¶: {output.shape}\")\n",
    "    \n",
    "    # æ‰‹åŠ¨è®¡ç®—éªŒè¯\n",
    "    manual_output = torch.matmul(input_data, linear.weight.T) + linear.bias\n",
    "    print(f\"\\nâœ… æ‰‹åŠ¨è®¡ç®—éªŒè¯:\")\n",
    "    print(f\"   y = xW^T + b\")\n",
    "    print(f\"   æ‰‹åŠ¨è®¡ç®—ç»“æœ: {manual_output}\")\n",
    "    print(f\"   æ˜¯å¦ç›¸ç­‰: {torch.allclose(output, manual_output)}\")\n",
    "\n",
    "def batch_processing():\n",
    "    \"\"\"æ‰¹å¤„ç†ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\nğŸ“¦ æ‰¹å¤„ç†ç¤ºä¾‹\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # åˆ›å»ºçº¿æ€§å±‚\n",
    "    linear = nn.Linear(4, 2)\n",
    "    \n",
    "    # å•ä¸ªæ ·æœ¬\n",
    "    single_input = torch.randn(4)\n",
    "    single_output = linear(single_input)\n",
    "    print(f\"å•ä¸ªæ ·æœ¬:\")\n",
    "    print(f\"   è¾“å…¥å½¢çŠ¶: {single_input.shape}\")\n",
    "    print(f\"   è¾“å‡ºå½¢çŠ¶: {single_output.shape}\")\n",
    "    \n",
    "    # æ‰¹å¤„ç†\n",
    "    batch_input = torch.randn(3, 4)  # 3ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ª4ç»´\n",
    "    batch_output = linear(batch_input)\n",
    "    print(f\"\\næ‰¹å¤„ç†:\")\n",
    "    print(f\"   è¾“å…¥å½¢çŠ¶: {batch_input.shape}\")\n",
    "    print(f\"   è¾“å‡ºå½¢çŠ¶: {batch_output.shape}\")\n",
    "    \n",
    "    # æ›´é«˜ç»´åº¦çš„æ‰¹å¤„ç†\n",
    "    high_dim_input = torch.randn(2, 5, 4)  # [batch, seq, features]\n",
    "    high_dim_output = linear(high_dim_input)\n",
    "    print(f\"\\né«˜ç»´æ‰¹å¤„ç†:\")\n",
    "    print(f\"   è¾“å…¥å½¢çŠ¶: {high_dim_input.shape}\")\n",
    "    print(f\"   è¾“å‡ºå½¢çŠ¶: {high_dim_output.shape}\")\n",
    "    print(f\"   ğŸ“ æ³¨æ„: Linearåªå¯¹æœ€åä¸€ç»´è¿›è¡Œå˜æ¢\")\n",
    "\n",
    "def parameter_initialization():\n",
    "    \"\"\"å‚æ•°åˆå§‹åŒ–ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\nğŸ² å‚æ•°åˆå§‹åŒ–\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # é»˜è®¤åˆå§‹åŒ–\n",
    "    linear_default = nn.Linear(3, 2)\n",
    "    print(f\"é»˜è®¤åˆå§‹åŒ–:\")\n",
    "    print(f\"   æƒé‡èŒƒå›´: [{linear_default.weight.min():.3f}, {linear_default.weight.max():.3f}]\")\n",
    "    print(f\"   åç½®èŒƒå›´: [{linear_default.bias.min():.3f}, {linear_default.bias.max():.3f}]\")\n",
    "    \n",
    "    # Xavieråˆå§‹åŒ–\n",
    "    linear_xavier = nn.Linear(3, 2)\n",
    "    nn.init.xavier_uniform_(linear_xavier.weight)\n",
    "    nn.init.zeros_(linear_xavier.bias)\n",
    "    print(f\"\\nXavieråˆå§‹åŒ–:\")\n",
    "    print(f\"   æƒé‡èŒƒå›´: [{linear_xavier.weight.min():.3f}, {linear_xavier.weight.max():.3f}]\")\n",
    "    print(f\"   åç½®: {linear_xavier.bias}\")\n",
    "    \n",
    "    # è‡ªå®šä¹‰åˆå§‹åŒ–\n",
    "    linear_custom = nn.Linear(3, 2)\n",
    "    with torch.no_grad():\n",
    "        linear_custom.weight.fill_(0.1)\n",
    "        linear_custom.bias.fill_(0.0)\n",
    "    print(f\"\\nè‡ªå®šä¹‰åˆå§‹åŒ–:\")\n",
    "    print(f\"   æƒé‡:\\n{linear_custom.weight}\")\n",
    "    print(f\"   åç½®: {linear_custom.bias}\")\n",
    "\n",
    "def no_bias_example():\n",
    "    \"\"\"æ— åç½®ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\nğŸš« æ— åç½®å±‚\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # åˆ›å»ºæ— åç½®çš„çº¿æ€§å±‚\n",
    "    linear_no_bias = nn.Linear(3, 2, bias=False)\n",
    "    \n",
    "    print(f\"æ— åç½®çº¿æ€§å±‚:\")\n",
    "    print(f\"   æƒé‡å½¢çŠ¶: {linear_no_bias.weight.shape}\")\n",
    "    print(f\"   æ˜¯å¦æœ‰åç½®: {linear_no_bias.bias is not None}\")\n",
    "    \n",
    "    # å¯¹æ¯”æœ‰åç½®å’Œæ— åç½®\n",
    "    linear_with_bias = nn.Linear(3, 2, bias=True)\n",
    "    \n",
    "    input_data = torch.randn(1, 3)\n",
    "    output_no_bias = linear_no_bias(input_data)\n",
    "    output_with_bias = linear_with_bias(input_data)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š å¯¹æ¯”:\")\n",
    "    print(f\"   è¾“å…¥: {input_data}\")\n",
    "    print(f\"   æ— åç½®è¾“å‡º: {output_no_bias}\")\n",
    "    print(f\"   æœ‰åç½®è¾“å‡º: {output_with_bias}\")\n",
    "\n",
    "def mlp_example():\n",
    "    \"\"\"å¤šå±‚æ„ŸçŸ¥æœºç¤ºä¾‹\"\"\"\n",
    "    print(\"\\nğŸ§  å¤šå±‚æ„ŸçŸ¥æœº (MLP)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    class SimpleMLP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size):\n",
    "            super().__init__()\n",
    "            self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "            self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "            self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    \n",
    "    # åˆ›å»ºMLP\n",
    "    mlp = SimpleMLP(input_size=10, hidden_size=20, output_size=3)\n",
    "    \n",
    "    print(f\"MLPç»“æ„:\")\n",
    "    print(mlp)\n",
    "    \n",
    "    # ç»Ÿè®¡å‚æ•°\n",
    "    total_params = sum(p.numel() for p in mlp.parameters())\n",
    "    print(f\"\\nğŸ“Š å‚æ•°ç»Ÿè®¡:\")\n",
    "    for name, param in mlp.named_parameters():\n",
    "        print(f\"   {name}: {param.shape} -> {param.numel()} ä¸ªå‚æ•°\")\n",
    "    print(f\"   æ€»å‚æ•°é‡: {total_params}\")\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    input_data = torch.randn(5, 10)  # 5ä¸ªæ ·æœ¬\n",
    "    output = mlp(input_data)\n",
    "    print(f\"\\nâš¡ å‰å‘ä¼ æ’­:\")\n",
    "    print(f\"   è¾“å…¥å½¢çŠ¶: {input_data.shape}\")\n",
    "    print(f\"   è¾“å‡ºå½¢çŠ¶: {output.shape}\")\n",
    "\n",
    "def transformer_linear_usage():\n",
    "    \"\"\"Transformerä¸­çš„Linearå±‚ä½¿ç”¨\"\"\"\n",
    "    print(\"\\nğŸ¤– Transformerä¸­çš„Linearå±‚\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    d_model = 512\n",
    "    heads = 8\n",
    "    d_k = d_model // heads\n",
    "    \n",
    "    print(f\"Transformerå‚æ•°:\")\n",
    "    print(f\"   d_model: {d_model}\")\n",
    "    print(f\"   heads: {heads}\")\n",
    "    print(f\"   d_k: {d_k}\")\n",
    "    \n",
    "    # æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„Linearå±‚\n",
    "    q_linear = nn.Linear(d_model, d_model)\n",
    "    k_linear = nn.Linear(d_model, d_model)\n",
    "    v_linear = nn.Linear(d_model, d_model)\n",
    "    out_linear = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    print(f\"\\nğŸ” æ³¨æ„åŠ›çº¿æ€§å±‚:\")\n",
    "    print(f\"   Qçº¿æ€§å±‚: {d_model} -> {d_model}\")\n",
    "    print(f\"   Kçº¿æ€§å±‚: {d_model} -> {d_model}\")\n",
    "    print(f\"   Vçº¿æ€§å±‚: {d_model} -> {d_model}\")\n",
    "    print(f\"   è¾“å‡ºå±‚: {d_model} -> {d_model}\")\n",
    "    \n",
    "    # å‰é¦ˆç½‘ç»œä¸­çš„Linearå±‚\n",
    "    d_ff = 2048\n",
    "    ff_linear1 = nn.Linear(d_model, d_ff)\n",
    "    ff_linear2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    print(f\"\\nğŸ½ï¸ å‰é¦ˆç½‘ç»œ:\")\n",
    "    print(f\"   ç¬¬ä¸€å±‚: {d_model} -> {d_ff}\")\n",
    "    print(f\"   ç¬¬äºŒå±‚: {d_ff} -> {d_model}\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ•°æ®æµ\n",
    "    batch_size, seq_len = 2, 10\n",
    "    input_tensor = torch.randn(batch_size, seq_len, d_model)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æ•°æ®æµ:\")\n",
    "    print(f\"   è¾“å…¥: {input_tensor.shape}\")\n",
    "    \n",
    "    # æ³¨æ„åŠ›è®¡ç®—\n",
    "    q = q_linear(input_tensor)\n",
    "    k = k_linear(input_tensor)\n",
    "    v = v_linear(input_tensor)\n",
    "    print(f\"   Q,K,V: {q.shape}\")\n",
    "    \n",
    "    # å‰é¦ˆç½‘ç»œ\n",
    "    ff_output = ff_linear2(F.relu(ff_linear1(input_tensor)))\n",
    "    print(f\"   å‰é¦ˆè¾“å‡º: {ff_output.shape}\")\n",
    "\n",
    "def practical_tips():\n",
    "    \"\"\"å®ç”¨æŠ€å·§\"\"\"\n",
    "    print(\"\\nğŸ’¡ å®ç”¨æŠ€å·§\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"ğŸ¯ é€‰æ‹©è¾“å…¥è¾“å‡ºç»´åº¦:\")\n",
    "    print(\"   - è¾“å…¥ç»´åº¦å¿…é¡»ä¸æ•°æ®æœ€åä¸€ç»´åŒ¹é…\")\n",
    "    print(\"   - è¾“å‡ºç»´åº¦æ ¹æ®ä»»åŠ¡éœ€æ±‚ç¡®å®š\")\n",
    "    print(\"   - å¸¸ç”¨ç»´åº¦: 64, 128, 256, 512, 768, 1024\")\n",
    "    \n",
    "    print(\"\\nğŸ”§ å‚æ•°åˆå§‹åŒ–:\")\n",
    "    print(\"   - é»˜è®¤: Kaimingåˆå§‹åŒ– (é€‚åˆReLU)\")\n",
    "    print(\"   - Xavier: é€‚åˆSigmoid/Tanh\")\n",
    "    print(\"   - è‡ªå®šä¹‰: æ ¹æ®å…·ä½“éœ€æ±‚\")\n",
    "    \n",
    "    print(\"\\nâš¡ æ€§èƒ½ä¼˜åŒ–:\")\n",
    "    print(\"   - æ‰¹å¤„ç†æé«˜æ•ˆç‡\")\n",
    "    print(\"   - GPUåŠ é€Ÿè®¡ç®—\")\n",
    "    print(\"   - æ··åˆç²¾åº¦è®­ç»ƒ\")\n",
    "    \n",
    "    print(\"\\nğŸ› å¸¸è§é”™è¯¯:\")\n",
    "    print(\"   - ç»´åº¦ä¸åŒ¹é…: æ£€æŸ¥in_features\")\n",
    "    print(\"   - æ¢¯åº¦æ¶ˆå¤±: æ³¨æ„åˆå§‹åŒ–å’Œæ¿€æ´»å‡½æ•°\")\n",
    "    print(\"   - è¿‡æ‹Ÿåˆ: æ·»åŠ dropoutæˆ–æ­£åˆ™åŒ–\")\n",
    "\n",
    "def linear_vs_conv():\n",
    "    \"\"\"Linear vs Conv å¯¹æ¯”\"\"\"\n",
    "    print(\"\\nğŸ†š Linear vs Conv å¯¹æ¯”\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Linearå±‚ - å…¨è¿æ¥\n",
    "    linear = nn.Linear(784, 10)  # MNISTåˆ†ç±»\n",
    "    print(f\"Linearå±‚ (å…¨è¿æ¥):\")\n",
    "    print(f\"   å‚æ•°é‡: {784 * 10 + 10:,}\")\n",
    "    print(f\"   ç‰¹ç‚¹: æ¯ä¸ªè¾“å…¥éƒ½è¿æ¥åˆ°æ¯ä¸ªè¾“å‡º\")\n",
    "    \n",
    "    # Convå±‚ - å±€éƒ¨è¿æ¥\n",
    "    conv = nn.Conv2d(1, 10, kernel_size=3)\n",
    "    print(f\"\\nConvå±‚ (å·ç§¯):\")\n",
    "    print(f\"   å‚æ•°é‡: {1 * 10 * 3 * 3 + 10}\")\n",
    "    print(f\"   ç‰¹ç‚¹: å±€éƒ¨è¿æ¥ï¼Œæƒé‡å…±äº«\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ä½¿ç”¨åœºæ™¯:\")\n",
    "    print(\"   Linear: åˆ†ç±»å±‚ã€å…¨è¿æ¥ç½‘ç»œã€Transformer\")\n",
    "    print(\"   Conv: å›¾åƒå¤„ç†ã€ç‰¹å¾æå–ã€CNN\")\n",
    "\n",
    "def debug_linear():\n",
    "    \"\"\"è°ƒè¯•Linearå±‚\"\"\"\n",
    "    print(\"\\nğŸ”§ è°ƒè¯•Linearå±‚\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    linear = nn.Linear(5, 3)\n",
    "    \n",
    "    # æ£€æŸ¥å‚æ•°\n",
    "    print(\"ğŸ” å‚æ•°æ£€æŸ¥:\")\n",
    "    print(f\"   æƒé‡æ˜¯å¦éœ€è¦æ¢¯åº¦: {linear.weight.requires_grad}\")\n",
    "    print(f\"   åç½®æ˜¯å¦éœ€è¦æ¢¯åº¦: {linear.bias.requires_grad}\")\n",
    "    print(f\"   æƒé‡æ¢¯åº¦: {linear.weight.grad}\")\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    input_data = torch.randn(2, 5, requires_grad=True)\n",
    "    output = linear(input_data)\n",
    "    \n",
    "    # åå‘ä¼ æ’­\n",
    "    loss = output.sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    print(f\"\\nâš¡ æ¢¯åº¦ä¿¡æ¯:\")\n",
    "    print(f\"   è¾“å…¥æ¢¯åº¦å½¢çŠ¶: {input_data.grad.shape}\")\n",
    "    print(f\"   æƒé‡æ¢¯åº¦å½¢çŠ¶: {linear.weight.grad.shape}\")\n",
    "    print(f\"   åç½®æ¢¯åº¦å½¢çŠ¶: {linear.bias.grad.shape}\")\n",
    "    \n",
    "    # æ¢¯åº¦æ£€æŸ¥\n",
    "    print(f\"\\nâœ… æ¢¯åº¦æ£€æŸ¥:\")\n",
    "    print(f\"   æƒé‡æ¢¯åº¦èŒƒå›´: [{linear.weight.grad.min():.4f}, {linear.weight.grad.max():.4f}]\")\n",
    "    print(f\"   æ˜¯å¦æœ‰NaN: {torch.isnan(linear.weight.grad).any()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸ‰ nn.Linear å®Œå…¨ä½¿ç”¨æŒ‡å—\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹\n",
    "    basic_linear_layer()\n",
    "    batch_processing()\n",
    "    parameter_initialization()\n",
    "    no_bias_example()\n",
    "    mlp_example()\n",
    "    transformer_linear_usage()\n",
    "    practical_tips()\n",
    "    linear_vs_conv()\n",
    "    debug_linear()\n",
    "    \n",
    "    print(\"\\nğŸŠ nn.Linear æ•™ç¨‹å®Œæˆ!\")\n",
    "    print(\"è®°ä½: Linearå±‚å°±æ˜¯ y = xW^T + b çš„çŸ©é˜µè¿ç®—ï¼\")\n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel-dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
