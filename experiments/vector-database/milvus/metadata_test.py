import ollama  # å¯¼å…¥ ollama åº“
from ollama import Client

from pymilvus import (
    connections,
    utility,
    FieldSchema,
    CollectionSchema,
    DataType,
    Collection,
)

# --- 1. é…ç½®ä¿¡æ¯ (é‡è¦ï¼šä¿®æ”¹äº†ç»´åº¦) ---
MILVUS_HOST = "localhost"
MILVUS_PORT = "19530"
OLLAMA_HOST = "localhost"
OLLAMA_PORT = "11434"
OLLAMA_MODEL_NAME = "bge-m3"  # æŒ‡å®šè¦ä½¿ç”¨çš„ Ollama æ¨¡å‹
COLLECTION_NAME = "my_articles_bge_m3"  # å»ºè®®ä¸ºæ–°æ¨¡å‹ä½¿ç”¨æ–°é›†åˆ
DIMENSION = 1024  # âš ï¸ å…³é”®ä¿®æ”¹ï¼šbge-m3 çš„å‘é‡ç»´åº¦æ˜¯ 1024

# --- 2. è¿æ¥åˆ° Milvus ---
print("Connecting to Milvus...")
connections.connect("default", host=MILVUS_HOST, port=MILVUS_PORT)
print("âœ… Connected to Milvus.")

# --- 3. åˆ›å»ºé›†åˆ (å¦‚æœä¸å­˜åœ¨) ---
# é›†åˆçš„ schema å®šä¹‰ä¸ä¹‹å‰ç›¸åŒï¼Œåªæ˜¯ç»´åº¦å˜äº†
if not utility.has_collection(COLLECTION_NAME):
    print(f"Collection '{COLLECTION_NAME}' does not exist. Creating now...")
    fields = [
        FieldSchema(
            name="chunk_id", dtype=DataType.INT64, is_primary=True, auto_id=True
        ),
        FieldSchema(name="original_doc_url", dtype=DataType.VARCHAR, max_length=512),
        FieldSchema(name="publish_date", dtype=DataType.VARCHAR, max_length=20),
        FieldSchema(name="chunk_text", dtype=DataType.VARCHAR, max_length=65535),
        FieldSchema(name="chunk_vector", dtype=DataType.FLOAT_VECTOR, dim=DIMENSION),
    ]
    schema = CollectionSchema(
        fields, "A collection using bge-m3 embeddings from Ollama"
    )
    collection = Collection(COLLECTION_NAME, schema)

    print("Creating index for scalar fields...")
    collection.create_index(field_name="original_doc_url")
    collection.create_index(field_name="publish_date")

    print("Creating index for vector field...")
    index_params = {
        "metric_type": "L2",
        "index_type": "IVF_FLAT",
        "params": {"nlist": 128},
    }
    collection.create_index(field_name="chunk_vector", index_params=index_params)
    print("âœ… Collection and indexes created.")
else:
    print(f"Collection '{COLLECTION_NAME}' already exists.")
    collection = Collection(COLLECTION_NAME)

# --- 4. å‡†å¤‡æ•°æ®å¹¶å­˜å…¥ Milvus ---
print("\nPreparing and inserting data using Ollama...")

# æ¨¡æ‹Ÿä¸¤ç¯‡æ–‡ç« 
articles = [
    {
        "content": "Milvus is a powerful open-source vector database built for AI applications. It's highly scalable and can handle billions of vectors.",
        "metadata": {"url": "https://milvus.io/docs", "publish_date": "2024-05-20"},
    },
    {
        "content": "The new AI model, released yesterday, shows incredible performance on text generation tasks. This model was trained on a massive dataset.",
        "metadata": {
            "url": "https://example.com/new-ai-model",
            "publish_date": "2025-07-09",
        },
    },
]

entities_to_insert = []
ollama_client = Client(host=OLLAMA_HOST)

# ç®€å•çš„æŒ‰å¥å­åˆ‡å—
for article in articles:
    chunks = article["content"].split(". ")
    try:
        response = ollama_client.embed(model=OLLAMA_MODEL_NAME, input=chunks)
        embeddings = response["embeddings"]

        entities_to_insert.extend(
            {
                "original_doc_url": article["metadata"]["url"],
                "publish_date": article["metadata"]["publish_date"],
                "chunk_text": chunk,
                "chunk_vector": embedding,
            }
            for chunk, embedding in zip(chunks, embeddings)
        )
    except Exception as e:
        print(f"Error getting embedding from Ollama: {e}")

if entities_to_insert:
    collection.insert(entities_to_insert)
    collection.flush()
    print(f"âœ… Inserted {len(entities_to_insert)} chunks into Milvus.")
    print(f"Total entities in collection: {collection.num_entities}")

# --- 5. æ‰§è¡Œæœç´¢ï¼ ---
print("\n--- Performing Search ---")
collection.load()

query_text = "What is a vector database?"
# âš ï¸ å…³é”®ä¿®æ”¹ï¼šåŒæ ·ä½¿ç”¨ Ollama ç”ŸæˆæŸ¥è¯¢å‘é‡
query_vector = ollama_client.embed(model=OLLAMA_MODEL_NAME, input=query_text)[
    "embeddings"
][0]

# åœºæ™¯1: çº¯å‘é‡ç›¸ä¼¼åº¦æœç´¢
print("\nğŸ” Scenario 1: Pure vector similarity search...")
search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
results = collection.search(
    data=[query_vector],
    anns_field="chunk_vector",
    param=search_params,
    limit=3,
    output_fields=["chunk_text", "original_doc_url"],
)
for hit in results[0]:
    print(
        f"  - URL: {hit.entity.get('original_doc_url')}, Text: '{hit.entity.get('chunk_text')}', Distance: {hit.distance:.4f}"
    )

# åœºæ™¯2: å‘é‡æœç´¢ + å…ƒæ•°æ®è¿‡æ»¤
print("\nğŸ” Scenario 2: Search with metadata filter (date = 2024-05-20)...")
filter_expression = 'publish_date == "2024-05-20"'
results_filtered = collection.search(
    data=[query_vector],
    anns_field="chunk_vector",
    param=search_params,
    limit=3,
    expr=filter_expression,
    output_fields=["chunk_text", "original_doc_url", "publish_date"],
)
if not results_filtered[0]:
    print("  No results found for this filter.")
else:
    for hit in results_filtered[0]:
        print(
            f"  - URL: {hit.entity.get('original_doc_url')}, Date: {hit.entity.get('publish_date')}, Text: '{hit.entity.get('chunk_text')}', Distance: {hit.distance:.4f}"
        )

# --- 6. é‡Šæ”¾èµ„æº ---
# collection.release()
connections.disconnect("default")
print("\nâœ… Done. Disconnected from Milvus.")
