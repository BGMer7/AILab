{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Q网络\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, action_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        return self.fc(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2\n"
     ]
    }
   ],
   "source": [
    "# 创建环境\n",
    "env = gym.make('CartPole-v1')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "print(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建网络\n",
    "online_net = QNetwork(state_dim, action_dim)\n",
    "target_net = QNetwork(state_dim, action_dim)\n",
    "target_net.load_state_dict(online_net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建优化器\n",
    "optimizer = optim.Adam(online_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "online_net.to(device)\n",
    "target_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建经验回放缓冲区\n",
    "replay_buffer = deque(maxlen=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置超参数\n",
    "epsilon = 1.0  # 探索率\n",
    "epsilon_decay = 0.995  # 探索率衰减\n",
    "min_epsilon = 0.01  # 最小探索率\n",
    "gamma = 0.99  # 折扣因子\n",
    "batch_size = 64  # 批大小\n",
    "update_target_every = 100  # 更新目标网络的频率\n",
    "max_steps = 10000  # 最大步数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DevKits\\Anaconda3\\envs\\dl\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# 训练过程\n",
    "for step in range(max_steps):\n",
    "    # 选择动作\n",
    "    state, _ = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    # epsilon-greedy策略\n",
    "    if np.random.rand() < epsilon:\n",
    "        action = env.action_space.sample()  # 探索\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            action = torch.argmax(online_net(state)).item()  # 利用\n",
    "\n",
    "    # 执行动作并存储转移\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated  # 合并终止和截断条件\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    reward = torch.tensor([reward], dtype=torch.float32).to(device)\n",
    "    replay_buffer.append((state, action, reward, next_state, done))\n",
    "    state = next_state\n",
    "\n",
    "    # 学习\n",
    "    if len(replay_buffer) >= batch_size:\n",
    "        minibatch = random.sample(replay_buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*minibatch)\n",
    "        states = torch.cat(states).to(device)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).unsqueeze(1).to(device)\n",
    "        rewards = torch.cat(rewards).to(device)\n",
    "        next_states = torch.cat(next_states).to(device)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32).to(device)\n",
    "\n",
    "        q_values = online_net(states).gather(1, actions)\n",
    "        with torch.no_grad():\n",
    "            max_next_q_values = target_net(next_states).max(1)[0]\n",
    "            target_q_values = rewards + gamma * (1 - dones) * max_next_q_values\n",
    "\n",
    "        loss = nn.functional.mse_loss(q_values, target_q_values.unsqueeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 更新目标网络\n",
    "        if step % update_target_every == 0:\n",
    "            target_net.load_state_dict(online_net.state_dict())\n",
    "\n",
    "    # 更新探索率\n",
    "    epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "\n",
    "    # 检查是否完成\n",
    "    if done:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel-dl",
   "language": "python",
   "name": "ipykernel-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
