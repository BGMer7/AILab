{"cells":[{"cell_type":"markdown","source":"# kernel design","id":"29b89274de261495"},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torchvision import datasets, transforms\n","from PIL import Image\n","import torch.nn as nn\n","import cv2"],"id":"a1c29779b11ff1f"},{"cell_type":"code","source":["img = Image.open('../data/lena.png')\n","img"],"id":"c6613d8e9a28f9a8"},{"cell_type":"code","source":["gray_image = transforms.Grayscale()(img)\n","gray_image"],"id":"e55af160ae92446"},{"cell_type":"code","source":["# 转换图片为 Tensor，缩放到 (224, 224)，并归一化\n","# Resize: 224这个归一化的标准有一定的历史原因\n","# Normalize: \n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5], std=[0.224])\n","])\n","\n","img_tensor = transform(gray_image)\n","img_tensor"],"id":"7fd83dbb50f993dd"},{"cell_type":"markdown","source":["在 PyTorch 中，`Normalize` 是图像预处理中的常见操作，通常用于标准化图像数据。`Normalize` 函数的参数决定了如何对图像的每个通道进行归一化，具体是通过均值和标准差来实现的。其作用是将图像的像素值变换为均值为 0、标准差为 1 的标准分布，以加快模型的收敛速度并提高模型的性能。\n","\n","### `transforms.Normalize(mean, std)` 参数的意义\n","- **mean**：图像每个通道的均值，用于将该通道的像素值从原始范围中平移。\n","- **std**：图像每个通道的标准差，用于缩放该通道的像素值。\n","\n","具体来说，对输入的图像，`Normalize` 的公式如下：\n","\n","$$\n","\\text{output} = \\frac{\\text{input} - \\text{mean}}{\\text{std}}\n","$$\n","\n","其中 `input` 是图像的像素值，`mean` 和 `std` 分别是各个通道的均值和标准差。\n","\n","### 举例\n","假设你有一个 RGB 图像，标准化的参数为：\n","\n","```python\n","transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","```\n","\n","这意味着图像的每个通道（红色、绿色、蓝色）的像素值会按以下公式进行处理：\n","\n","$$\n","\\text{output}_{\\text{R}} = \\frac{\\text{input}_{\\text{R}} - 0.5}{0.5}\n","$$\n","$$\n","\\text{output}_{\\text{G}} = \\frac{\\text{input}_{\\text{G}} - 0.5}{0.5}\n","$$\n","$$\n","\\text{output}_{\\text{B}} = \\frac{\\text{input}_{\\text{B}} - 0.5}{0.5}\n","$$\n","\n","- **mean = [0.5, 0.5, 0.5]**：表示对每个通道的均值为 0.5 的像素值进行平移。\n","- **std = [0.5, 0.5, 0.5]**：表示对每个通道按 0.5 的标准差进行缩放。\n","\n","这样，原始像素值在 [0, 1] 之间的范围会被标准化到 [-1, 1] 之间。这种归一化对于大多数神经网络模型（尤其是预训练模型）都有利于模型训练。\n","\n","### 为什么需要 Normalize？\n","1. **加速模型训练**：标准化后的数据可以让模型更快收敛，因为它使得输入数据的尺度更统一。\n","2. **提升模型性能**：避免不同通道的数据值范围差异过大，有助于模型学到更有代表性的特征。\n","3. **适应预训练模型**：如果使用预训练模型，通常输入数据必须标准化为某种特定的均值和标准差（如 ImageNet 数据集上训练的模型常用 `[0.485, 0.456, 0.406]` 和 `[0.229, 0.224, 0.225]`）。\n","\n","### 常用的标准化参数\n","- 对于 ImageNet 数据集，通常使用的均值和标准差为：\n","\n","```python\n","transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","```\n","\n","这对应于 ImageNet 数据集中 RGB 三个通道的图像像素值分布。"],"id":"a293627518473117"},{"cell_type":"code","source":"img_tensor.size()","id":"cce13530b30e5c16"},{"cell_type":"markdown","source":"## 正交检测、直角检测","id":"9822a56496dbaaac"},{"cell_type":"markdown","source":"### Sobel Operator","id":"1994ca490417826a"},{"cell_type":"code","source":["# 定义 Sobel 水平方向卷积核\n","sobel_kernel_x = torch.tensor([[-1.0, 0.0, 1.0],\n","                               [-2.0, 0.0, 2.0],\n","                               [-1.0, 0.0, 1.0]])\n","\n","# 定义 Sobel 垂直方向卷积核\n","sobel_kernel_y = torch.tensor([[-1.0, -2.0, -1.0],\n","                               [0.0,  0.0,  0.0],\n","                               [1.0,  2.0,  1.0]])\n","\n","# 将卷积核扩展为适用于 PyTorch 的格式 (out_channels, in_channels, kernel_size, kernel_size)\n","sobel_kernel_x = sobel_kernel_x.expand(1, 1, 3, 3)\n","sobel_kernel_y = sobel_kernel_y.expand(1, 1, 3, 3)"],"id":"b74bf3bc6d4679be"},{"cell_type":"code","source":["# 定义 Sobel 卷积层\n","class SobelConv(nn.Module):\n","    def __init__(self):\n","        super(SobelConv, self).__init__()\n","        # 将 Sobel 核定义为固定的卷积层权重\n","        self.conv_x = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1, bias=False)\n","        self.conv_y = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1, bias=False)\n","        # 设置权重为 Sobel 核，并固定不更新\n","        self.conv_x.weight = nn.Parameter(sobel_kernel_x, requires_grad=False)\n","        self.conv_y.weight = nn.Parameter(sobel_kernel_y, requires_grad=False)\n","\n","    def forward(self, x):\n","        # 使用水平方向和垂直方向的 Sobel 核卷积\n","        grad_x = self.conv_x(x)\n","        grad_y = self.conv_y(x)\n","        # 返回梯度的幅值\n","        grad = torch.sqrt(grad_x**2 + grad_y**2)\n","        return grad"],"id":"f27e1b0919bb07d"},{"cell_type":"code","source":["# 定义 Sobel 算子的卷积核\n","sobel_x = torch.tensor([[-1., 0., 1.],\n","                        [-2., 0., 2.],\n","                        [-1., 0., 1.]]).view(1, 1, 3, 3)\n","sobel_x"],"id":"7bcfbfdee3b1590f"},{"cell_type":"code","source":["sobel_y = torch.tensor([[-1., -2., -1.],\n","                        [0., 0., 0.],\n","                        [1., 2., 1.]]).view(1, 1, 3, 3)\n","sobel_y"],"id":"b6baff8a94cdc839"},{"cell_type":"code","source":["# 使用 Sobel 卷积核分别检测水平和垂直边缘\n","output_x = F.conv2d(img_tensor, sobel_x)\n","output_x.shape"],"id":"49c9329de2654d5e"},{"cell_type":"code","source":["output_y = F.conv2d(img_tensor, sobel_y)\n","output_y.shape"],"id":"e7f8c4b38c8be4c1"},{"cell_type":"code","source":"output = torch.sqrt(output_x**2 + output_y**2)","id":"f1c289f24ecb6190"},{"cell_type":"code","source":["# 转换为 NumPy 格式并移除批次和通道维度\n","output_image_np = output.squeeze().detach().numpy()\n","\n","# 绘制合并后的梯度幅值图像\n","plt.imshow(output_image_np, cmap='gray')\n","plt.title(\"Edge Detection using Sobel Operator\")\n","plt.show()"],"id":"ed44e405e0252dc8"},{"cell_type":"markdown","source":"## blur kernel","id":"49374c0eec799818"},{"cell_type":"code","source":["# 定义一个模糊卷积核\n","box_blur_kernel = torch.tensor([[1.0, 1.0, 1.0], \n","                                [1.0, 1.0, 1.0], \n","                                [1.0, 1.0, 1.0]]) / 9.0"],"id":"8efd8e7fd8bbd0bd"},{"cell_type":"code","source":["gaussian_blur_kernel = torch.tensor([[1.0, 2.0, 1.0], \n","                                     [2.0, 4.0, 2.0], \n","                                     [1.0, 2.0, 1.0]]) / 16.0"],"id":"7d9e86bfa1e14962"},{"cell_type":"code","source":["# 将 kernel 扩展为 4D 张量，以用于 2D 卷积\n","box_blur_kernel = box_blur_kernel.expand(1, 1, 3, 3)\n","gaussian_blur_kernel = gaussian_blur_kernel.expand(1, 1, 3, 3)"],"id":"f8ea9a0588656ff6"},{"cell_type":"code","source":["# 定义模糊卷积层\n","class BlurConv(nn.Module):\n","    def __init__(self, kernel):\n","        super(BlurConv, self).__init__()\n","        self.conv = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\n","        self.conv.weight = nn.Parameter(kernel, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.conv(x)"],"id":"c37f4ec884f82273"},{"cell_type":"code","source":["# 创建模糊卷积层\n","box_blur_conv = BlurConv(box_blur_kernel)\n","gaussian_blur_conv = BlurConv(gaussian_blur_kernel)"],"id":"629463d7ab38b28b"},{"cell_type":"code","source":["output = box_blur_conv(img_tensor)\n","output.shape"],"id":"6b53586e5d6884e4"},{"cell_type":"code","source":["# 转换为 NumPy 格式并移除批次和通道维度\n","output_image_np = output.squeeze().detach().numpy()\n","\n","# 绘制合并后的梯度幅值图像\n","plt.imshow(output_image_np, cmap='gray')\n","plt.title(\"Box Blur Convolution\")\n","plt.show()"],"id":"e9f543b358379715"},{"cell_type":"code","source":["output = gaussian_blur_conv(img_tensor)\n","output.shape"],"id":"4b0752232220923f"},{"cell_type":"code","source":["# 转换为 NumPy 格式并移除批次和通道维度\n","output_image_np = output.squeeze().detach().numpy()\n","\n","# 绘制合并后的梯度幅值图像\n","plt.imshow(output_image_np, cmap='gray')\n","plt.title(\"Gaussian Blur Convolution\")\n","plt.show()"],"id":"b4306ec93e8b8c57"},{"cell_type":"code","source":"","id":"adc19de344a6c177"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":5}
