{"cells":[{"cell_type":"markdown","source":"# 8.2. Networks Using Blocks (VGG)","id":"b5e5a013cf13b00e"},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from d2l import torch as d2l\n","from d2l import plt as plt"],"id":"612a4e4431e9e179"},{"cell_type":"markdown","source":"## 8.2.1. VGG Blocks","id":"91d129994e778c51"},{"cell_type":"markdown","source":["The basic building block of CNNs is a sequence of the following:\n","\n","1. a convolutional layer with padding to maintain the resolution\n","2. a nonlinearity such as a ReLU\n","3. a pooling layer such as max-pooling to reduce the resolution\n"],"id":"59c8ea1dc1a56b68"},{"cell_type":"code","source":["def vgg_block(num_convs, out_channels):\n","    layers = []\n","    \n","    for _ in range(num_convs):\n","        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n","        layers.append(nn.ReLU())\n","    \n","    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n","    return nn.Sequential(*layers)"],"id":"4a6036d7dc982c2b"},{"cell_type":"markdown","source":["### VGG block\n","3x3 Conv, padding 1\n","\n","2x2 MaxPooling, stride 2"],"id":"c2cee5d47b9cac1f"},{"cell_type":"markdown","source":"原始VGG网络有5个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。 第一个模块有64个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到512。由于该网络使用8个卷积层和3个全连接层，因此它通常被称为VGG-11。","id":"e56b8e926679a52"},{"cell_type":"code","source":"conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))","id":"4b08a1701e3ea3eb"},{"cell_type":"code","source":["def vgg(num_convs, num_out_channels):\n","    net = []\n","    for _ in range(num_convs):\n","        # 3x3 conv, padding 1\n","        net.append(nn.LazyConv2d(num_out_channels, kernel_size = 3, padding = 1))\n","        # 2x2 MaxPooling, stride 2\n","        net.append(nn.MaxPool2d(kernel_size=2, stride=2))\n","    \n","    return nn.Sequential(*net) "],"id":"330f2983b26435e2"},{"cell_type":"markdown","source":"## 8.2.2. VGG Network","id":"a20375b20e047e83"},{"cell_type":"code","source":["class VGG(d2l.Classifier):\n","    def __init__(self, arch, lr=0.1, num_classes=10):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        conv_blks = []\n","        for (num_convs, out_channels) in arch:\n","            conv_blks.append(vgg_block(num_convs, out_channels))\n","        self.net = nn.Sequential(\n","            *conv_blks, nn.Flatten(),\n","            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n","            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n","            nn.LazyLinear(num_classes))\n","        self.net.apply(d2l.init_cnn)"],"id":"17834a22292b2032"},{"cell_type":"code","source":["VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))).layer_summary(\n","    (1, 1, 224, 224))"],"id":"1e4c6cfd9407a054"},{"cell_type":"markdown","source":"## 8.2.3. Training","id":"46d0d62d56cadedf"},{"cell_type":"code","source":["model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01)\n","trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n","data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n","model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n","trainer.fit(model, data)"],"id":"d24a4e02500f0b67"},{"cell_type":"code","source":"","id":"e243becffb41b63d"}],"metadata":{"kernelspec":{"display_name":"ipykernel-d2l","language":"python","name":"ipykernel-d2l"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":5}
